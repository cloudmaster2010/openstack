# Introduction(this page is under construction)
This page is to demonstrate how to set the configuration of OpenStack zun, kata, kuryr project, and nfs storage backend. 
After these configurations, we can verify some functions like the following: 
 1. docker network
 2. zun container service
 3. kata runtime
 4. kuryr network for vm and container
 5. nfs volume service
 6. VMs with nfs volumes
 7. containers with nfs volumes
 8. Network verification between containers

# What are zun, kata, kuryr project?
## What is zun?
Zun is the OpenStack container service project, which aims to provide an API service for running application containers without managing servers or clusters.
Containers managed by zun are integrated with other OpenStack components, such as Neutron, Cinder, Glance, and Keystone. 

![image](https://wiki.openstack.org/w/images/thumb/1/13/OpenStack-zun-image.jpeg/600px-OpenStack-zun-image.jpeg)   
Figure 1. Zun Conceptual Architecture[1]


## What is kata container?
Kata container is an open source project working to build a secure container runtime with lightweight virtual machines that feel and perform like containers.
Kata container is an OCI compatiable runtime, ahdn thus plugs into both Docker and Kubenetes.

![image](./images/3.kataimg.png)   
Figure 1. Kata Container Conceptual Architecture[2]

## What is kuryr?
Kuryr aims to be the integrations bridge between Docker and Neutron project to be able to fullfill the use cases needed spcifically to containers networking.
Kuryr leverage Neutron abstraction to be able to create virtual networks for containers.[3]

# How to install kata, zun, and kuryr.
You are easily able to install them together by following instructions from the link below.      
https://github.com/cloudmaster2010/openstack/blob/main/devstack/1.openstack-with-dev.md

# Setting nfs storage backend to use cinder volume service on containers.
## Setting nfs server   
Set the configuration to allow 172.17.1.0/24 traffics that is requested from OpenStack Cinser Service.    
```sh
$ cat /etc/exports   
/dev_nfs 172.17.1.0/24(rw,sync,no_root_squash)
```

## Setting Cinder Volume on OpenStack   

```sh
$ cat /etc/cinder/cinder.conf
[DEFAULT]
...
default_volume_type = nfs-1
enabled_backends = nfs-1
...

[nfs-1]
volume_driver = cinder.volume.drivers.nfs.NfsDriver
volume_backend_name = nfs-1
nfs_shares_config = /etc/cinder/nfs_shares
nfs_snapshot_support = True
nas_secure_file_permissions = False
nas_secure_file_operations = False
```

Update the nfs path to be defined in /etc/cinder/nfs_shares.   
```sh
$ cat /etc/cinder/nfs_shares 
172.17.1.55:/dev_nfs
```

## Create volume type and backend   
```sh
$ openstack volume type create nfs
$ openstack volume type set --property volume_backend_name=nfs-1 nfs

$ openstack volume type list
+--------------------------------------+-------------+-----------+
| ID                                   | Name        | Is Public |
+--------------------------------------+-------------+-----------+
| 0090ec1d-fad2-40cc-b7f8-2e541e4b621c | __DEFAULT__ | True      |
| 26770e40-dc9e-4de9-8583-202371bf0fae | nfs         | True      |
+--------------------------------------+-------------+-----------+
$ openstack volume type show nfs
+--------------------+--------------------------------------+
| Field              | Value                                |
+--------------------+--------------------------------------+
| access_project_ids | None                                 |
| description        | None                                 |
| id                 | 26770e40-dc9e-4de9-8583-202371bf0fae |
| is_public          | True                                 |
| name               | nfs                                  |
| properties         | volume_backend_name='nfs-1'          |
| qos_specs_id       | None                                 |
+--------------------+--------------------------------------+
```

## Check if the volume servic is up   
```sh
$ openstack volume service list
+------------------+----------------------+------+---------+-------+----------------------------+
| Binary           | Host                 | Zone | Status  | State | Updated At                 |
+------------------+----------------------+------+---------+-------+----------------------------+
| cinder-scheduler | zun-kata-kuryr       | nova | enabled | up    | 2022-02-19T15:02:16.000000 |
| cinder-volume    | zun-kata-kuryr@nfs-1 | nova | enabled | up    | 2022-02-19T03:32:40.000000 |
+------------------+----------------------+------+---------+-------+----------------------------+
```

# Check configuration of kuryr service and whether related to daemons are ruuning. 
Check if the value is correct and path exists.     
```sh
$ egrep -v "^$|^#" /etc/kuryr/kuryr.conf 
[DEFAULT]
debug = True
bindir = /usr/local/libexec/kuryr
process_external_connectivity = False
capability_scope = global
[binding]
[neutron]
memcached_servers = localhost:11211
cafile = /opt/stack/data/ca-bundle.pem
project_domain_name = Default
project_name = service
user_domain_name = Default
password = password
username = kuryr
auth_url = http://172.17.1.110/identity
interface = public
auth_type = password

```

Check the kuryr-libnetwork.service is active (running).   
```sh
$ sudo systemctl status devstack@kuryr-libnetwork.service
â— devstack@kuryr-libnetwork.service - Devstack devstack@kuryr-libnetwork.service
     Loaded: loaded (/etc/systemd/system/devstack@kuryr-libnetwork.service; enabled; vendor preset: enab>
     Active: active (running) since Sat 2022-02-19 15:28:27 UTC; 7min ago
...
```

# Reference:
[1] https://wiki.openstack.org/wiki/Zun   
[2] https://katacontainers.io/   
[3] https://wiki.openstack.org/wiki/Kuryr
